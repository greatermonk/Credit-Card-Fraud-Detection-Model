{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyM0OpDSGp2wK8uRfTEdixyt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greatermonk/Credit-Card-Fraud-Detection-Model/blob/main/Credit_Card_Fraud_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pandas numpy matplotlib seaborn imblearn xgboost"
      ],
      "metadata": {
        "id": "9UCY7onThjO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MslqAA2pUd1K",
        "outputId": "6efac1d1-7393-4f40-c7b6-e0eef818c358"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
            "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
            "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
            "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
            "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
            "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
            "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
            "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
            "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
            "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
            "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
            "\n",
            "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
            "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
            "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
            "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
            "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
            "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
            "5  0.260314 -0.568671  ... -0.208254 -0.559825 -0.026398 -0.371427 -0.232794   \n",
            "6  0.081213  0.464960  ... -0.167716 -0.270710 -0.154104 -0.780055  0.750137   \n",
            "7 -3.807864  0.615375  ...  1.943465 -1.015455  0.057504 -0.649709 -0.415267   \n",
            "8  0.851084 -0.392048  ... -0.073425 -0.268092 -0.204233  1.011592  0.373205   \n",
            "9  0.069539 -0.736727  ... -0.246914 -0.633753 -0.120794 -0.385050 -0.069733   \n",
            "\n",
            "        V26       V27       V28  Amount  Class  \n",
            "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
            "1  0.125895 -0.008983  0.014724    2.69      0  \n",
            "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
            "3 -0.221929  0.062723  0.061458  123.50      0  \n",
            "4  0.502292  0.219422  0.215153   69.99      0  \n",
            "5  0.105915  0.253844  0.081080    3.67      0  \n",
            "6 -0.257237  0.034507  0.005168    4.99      0  \n",
            "7 -0.051634 -1.206921 -1.085339   40.80      0  \n",
            "8 -0.384157  0.011747  0.142404   93.20      0  \n",
            "9  0.094199  0.246219  0.083076    3.68      0  \n",
            "\n",
            "[10 rows x 31 columns]\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "raw_data = pd.read_csv('/content/drive/My Drive/Credit Card Model/creditcard.csv')\n",
        "print(raw_data.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Class Fraud Detection Model\n",
        "**Initialize 3 ML models to use:**\n",
        "\n",
        "\n",
        "\n",
        "1.   Random Forest\n",
        "2.   Logistic Regression(Classifier)\n",
        "3.   XGBoost\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kSK6kYKpV2y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FraudDetectionModel:\n",
        "    def __init__ (self):\n",
        "        self.models = {\n",
        "            'random_forest': RandomForestClassifier(random_state=42, n_jobs=-1),\n",
        "            'logistic_regression': LogisticRegression(random_state=42, max_iter=1000),\n",
        "            'xgboost': XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "        }\n",
        "        self.best_model = None\n",
        "        self.scaler = StandardScaler()"
      ],
      "metadata": {
        "id": "1lrDn2xSWbte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Loading & Data Preprocessing:**\n",
        "\n",
        "\n",
        "\n",
        "1.   Load the creditcard.csv file using pd.read_csv()\n",
        "2.   Separate Features & Targets\n",
        "3.   Split the data into:\n",
        "     - Train Set: X_train, y_train (80%),\n",
        "     - Test Set: X_test, y_test (20%)\n",
        "4.   Use StandardScaler class to scale the features   (Removing the mean & scaling to unit variance)\n",
        "\n",
        "5.   Return the Scaled features and target values.\n",
        "\n"
      ],
      "metadata": {
        "id": "jtNfTffzWcxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def load_and_preprocess(self, data_path=raw_data):\n",
        "        # Load the dataset\n",
        "        df = pd.read_csv(data_path)\n",
        "\n",
        "        # Separate features and target\n",
        "        X = df.drop('Class', axis=1)\n",
        "        y = df['Class']\n",
        "\n",
        "        # Split the data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, stratify=y\n",
        "        )\n",
        "\n",
        "        # Scale the features\n",
        "        self.scaler.fit(X_train)\n",
        "        X_train_scaled = self.scaler.transform(X_train)\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "\n",
        "        return X_train_scaled, X_test_scaled, y_train, y_test"
      ],
      "metadata": {
        "id": "K8nup5epX2wM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is SMOTE?\n",
        "**SMOTE** is a technique used to address class imbalance in datasets by generating synthetic samples of the minority class.\n",
        "\n",
        "We have 492 frauds out of 284,807 transactions (0.172% fraud rate)\n",
        "This extreme imbalance can make models biased towards the majority class (non-fraudulent transactions)\n",
        "\n",
        "**How SMOTE Works:**\n",
        "\n",
        "*For each minority class sample:*\n",
        "\n",
        "1. Find its k-nearest neighbors (default k=5) in the minority class.\n",
        "\n",
        "2. Randomly select one of these neighbors.\n",
        "\n",
        "3. Create a synthetic sample along the line between the original sample and the selected neighbor:\n",
        "\n",
        "**Returns:**\n",
        "\n",
        "- *X_train_balanced:* Features with synthetic samples added.\n",
        "- *y_train_balanced:* Corresponding balanced labels\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iVB8Jk11X4rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def apply_smote (self, X_train, y_train):\n",
        "        # Apply SMOTE to handle class imbalance\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
        "        return X_train_balanced, y_train_balanced"
      ],
      "metadata": {
        "id": "F3JcC0dkYuns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train And Evaluate**\n",
        "\n",
        "Train the models using preprocessed dataset.\n",
        "\n",
        "Also give the best model based on the F1 score."
      ],
      "metadata": {
        "id": "Zc3tzI3XY_gz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def train_and_evaluate (self, X_train, X_test, y_train, y_test):\n",
        "        results = {}\n",
        "\n",
        "        # Train and evaluate each model\n",
        "        for name, model in self.models.items():\n",
        "            print(f\"\\nTraining {name}...\")\n",
        "\n",
        "            # Train the model\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "            # Make predictions\n",
        "            y_pred = model.predict(X_test)\n",
        "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "            # Calculate metrics\n",
        "            results[name] = self.calculate_metrics(y_test, y_pred, y_pred_proba)\n",
        "\n",
        "        # Find the best model based on F1 score\n",
        "        best_model_name = max(results.items(), key=lambda x: x[1]['f1_score'])[0]\n",
        "        self.best_model = self.models[best_model_name]\n",
        "\n",
        "        return results"
      ],
      "metadata": {
        "id": "ALcnb0HdZwZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating Metrics**\n",
        "\n",
        "1. TN (True Negative): Model correctly predicts a negative class.\n",
        "2. FP (False Positive): Model incorrectly predicts a positive class.\n",
        "3. FN (False Negative): Model incorrectly predicts a negative class.\n",
        "4. TP (True Positive): Model correctly predicts a positive class.\n",
        "\n",
        "**A) Performance Metrics:**\n",
        "\n",
        "1. Accuracy: Overall proportion of correct predictions.\n",
        "2. Precision: Proportion of positive predictions that are actually positive.\n",
        "3. Recall (Sensitivity): Proportion of actual positive cases correctly identified.\n",
        "4. Specificity: Proportion of actual negative cases correctly identified.\n",
        "5. F1-score: Harmonic mean of precision and recall, balancing both metrics.\n",
        "\n",
        "**B) Visualization Tool:**\n",
        "\n",
        "1. ROC Curve (Receiver Operating Characteristic Curve): Plots the true positive rate (sensitivity) against the false positive rate (1-specificity) at various threshold settings.\n",
        "\n",
        "**Evaluation Matrix:**\n",
        "\n",
        "Confusion Matrix: A table that visualizes the performance of a classification model, showing correct and incorrect predictions for each class."
      ],
      "metadata": {
        "id": "Tb-TDzdAZzGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def calculate_metrics (self, y_true, y_pred, y_pred_proba):\n",
        "        # Calculate confusion matrix\n",
        "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "\n",
        "        # Calculate various metrics\n",
        "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "        precision = tp / (tp + fp)\n",
        "        recall = tp / (tp + fn)\n",
        "        specificity = tn / (tn + fp)\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "        # Calculate ROC curve and AUC\n",
        "        fpr, tpr, _ = roc_curve(y_true, y_pred_proba)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        # Calculate Precision-Recall curve and AUC\n",
        "        precision_curve, recall_curve, _ = precision_recall_curve(y_true, y_pred_proba)\n",
        "        pr_auc = auc(recall_curve, precision_curve)\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'specificity': specificity,\n",
        "            'f1_score': f1_score,\n",
        "            'roc_auc': roc_auc,\n",
        "            'pr_auc': pr_auc,\n",
        "            'confusion_matrix': {\n",
        "                'tn': tn, 'fp': fp,\n",
        "                'fn': fn, 'tp': tp\n",
        "            }\n",
        "        }"
      ],
      "metadata": {
        "id": "43CQhjiKa9D-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot The Results using matplotlib and seaborn library**\n",
        "\n",
        "This function provides a clear visual comparison of various model performance metrics and confusion matrices in a single figure."
      ],
      "metadata": {
        "id": "fkimDp_dbWeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def plot_results (self, results):\n",
        "        # Set up the plotting style\n",
        "        plt.style.use('ggplot')\n",
        "\n",
        "        # Create a figure with multiple subplots\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "        # Plot metrics comparison\n",
        "        metrics = ['accuracy', 'precision', 'recall', 'specificity']\n",
        "        model_names = list(results.keys())\n",
        "        metric_values = [[results[model][metric] for model in model_names] for metric in metrics]\n",
        "\n",
        "        # Bar plot for metrics\n",
        "        ax = axes[0, 0]\n",
        "        x = np.arange(len(model_names))\n",
        "        width = 0.2\n",
        "        for i, metric in enumerate(metrics):\n",
        "            ax.bar(x + i * width, [results[model][metric] for model in model_names],\n",
        "                   width, label=metric.capitalize())\n",
        "        ax.set_xticks(x + width * 1.5)\n",
        "        ax.set_xticklabels(model_names)\n",
        "        ax.set_title('Model Performance Metrics')\n",
        "        ax.legend()\n",
        "\n",
        "        # Plot confusion matrices\n",
        "        for i, (name, result) in enumerate(results.items()):\n",
        "            ax = axes[i // 2, i % 2 + 1] if i < 2 else axes[1, i - 2]\n",
        "            cm = np.array([[result['confusion_matrix']['tn'], result['confusion_matrix']['fp']],\n",
        "                           [result['confusion_matrix']['fn'], result['confusion_matrix']['tp']]])\n",
        "            sns.heatmap(cm, annot=True, fmt='d', ax=ax)\n",
        "            ax.set_title(f'Confusion Matrix - {name}')\n",
        "            ax.set_xlabel('Predicted')\n",
        "            ax.set_ylabel('Actual')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "e5UrlVSfbAc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main function\n",
        "\n",
        "- Initialize FraudDetectionModel() class.\n",
        "- Load And Preprocess the Data.\n",
        "- Train and Evaluate the data using different metrics.\n",
        "- Print the results.\n",
        "- Visualize the model predictions and conclusion."
      ],
      "metadata": {
        "id": "T8hjK0CMbnre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fraud_detector = FraudDetectionModel()\n",
        "\n",
        "    # Load and preprocess the data\n",
        "X_train, X_test, y_train, y_test = fraud_detector.load_and_preprocess()\n",
        "\n",
        "    # Apply SMOTE to handle class imbalance\n",
        "X_train_balanced, y_train_balanced = fraud_detector.apply_smote(X_train, y_train)\n",
        "\n",
        "    # Train and evaluate models\n",
        "results = fraud_detector.train_and_evaluate(X_train_balanced, X_test, y_train_balanced, y_test)\n",
        "\n",
        "    # Print results\n",
        "for model_name, metrics in results.items():\n",
        "  print(f\"\\nResults for {model_name}:\")\n",
        "  for metric_name, value in metrics.items():\n",
        "    if metric_name != 'confusion_matrix':\n",
        "      print(f\"{metric_name}: {value:.4f}\")\n",
        "\n",
        "\n",
        "fraud_detector.plot_results(results)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "W2_D8cZ1cJuV",
        "outputId": "97cce5b0-d851-49cb-b709-a1b3380be873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'FraudDetectionModel' object has no attribute 'load_and_preprocess'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-533746bfa5eb>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Load and preprocess the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfraud_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_and_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Apply SMOTE to handle class imbalance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'FraudDetectionModel' object has no attribute 'load_and_preprocess'"
          ]
        }
      ]
    }
  ]
}